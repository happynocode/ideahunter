-- Enable necessary extensions
CREATE EXTENSION IF NOT EXISTS "uuid-ossp";

-- Create users table
CREATE TABLE IF NOT EXISTS users (
  id SERIAL PRIMARY KEY,
  username VARCHAR(255) NOT NULL UNIQUE,
  email VARCHAR(255) NOT NULL UNIQUE,
  password_hash VARCHAR(255) NOT NULL,
  created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
  updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- Create industries table
CREATE TABLE IF NOT EXISTS industries (
  id SERIAL PRIMARY KEY,
  name VARCHAR(255) NOT NULL,
  slug VARCHAR(255) NOT NULL UNIQUE,
  icon VARCHAR(255),
  color VARCHAR(255),
  description TEXT,
  created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
  updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- Create raw_reddit_posts table - stores original scraped data
CREATE TABLE IF NOT EXISTS raw_reddit_posts (
  id SERIAL PRIMARY KEY,
  title VARCHAR(500) NOT NULL,
  content TEXT,
  author VARCHAR(255) NOT NULL,
  subreddit VARCHAR(255) NOT NULL,
  upvotes INTEGER DEFAULT 0,
  comments INTEGER DEFAULT 0,
  permalink VARCHAR(500) NOT NULL,
  reddit_id VARCHAR(255) NOT NULL UNIQUE,
  industry_id INTEGER REFERENCES industries(id),
  created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
  scraped_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
  analyzed BOOLEAN DEFAULT false,
  analyzed_at TIMESTAMP
);

-- Create startup_ideas table - stores AI-analyzed results
CREATE TABLE IF NOT EXISTS startup_ideas (
  id SERIAL PRIMARY KEY,
  title VARCHAR(500) NOT NULL,
  summary TEXT NOT NULL,
  industry_id INTEGER REFERENCES industries(id),
  upvotes INTEGER DEFAULT 0,
  comments INTEGER DEFAULT 0,
  keywords TEXT[] DEFAULT '{}',
  subreddit VARCHAR(255),
  reddit_post_urls TEXT[] DEFAULT '{}',
  existing_solutions TEXT,
  solution_gaps TEXT,
  market_size TEXT,
  confidence_score INTEGER DEFAULT 0,
  source_post_ids INTEGER[] DEFAULT '{}',
  created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
  updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- Create daily_stats table
CREATE TABLE IF NOT EXISTS daily_stats (
  id SERIAL PRIMARY KEY,
  date DATE NOT NULL UNIQUE,
  total_ideas INTEGER DEFAULT 0,
  new_industries INTEGER DEFAULT 0,
  avg_upvotes INTEGER DEFAULT 0,
  success_rate DECIMAL(5,2) DEFAULT 0,
  created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
  updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- Create scrape_tasks table
CREATE TABLE IF NOT EXISTS scrape_tasks (
  id SERIAL PRIMARY KEY,
  industry_id INTEGER NOT NULL,
  time_range VARCHAR(10) NOT NULL,
  status VARCHAR(20) NOT NULL DEFAULT 'pending_scrape',
  batch_id VARCHAR(100) NOT NULL,
  posts_scraped INTEGER DEFAULT 0,
  posts_processed INTEGER DEFAULT 0,
  ideas_generated INTEGER DEFAULT 0,
  retry_count INTEGER DEFAULT 0,
  max_retries INTEGER DEFAULT 3,
  error_message TEXT,
  created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
  started_at TIMESTAMP,
  completed_at TIMESTAMP
);

-- Insert 20 detailed industries based on PRD
INSERT INTO industries (name, slug, icon, color, description) VALUES
('SaaS & äº‘æœåŠ¡', 'saas-cloud', 'â˜ï¸', '#3b82f6', 'Software as a Service and cloud computing solutions'),
('å¼€å‘è€…å·¥å…· & å¹³å°', 'dev-tools', 'âš™ï¸', '#6b7280', 'Software development tools and platforms'),
('API & åç«¯æœåŠ¡', 'api-backend', 'ğŸ”—', '#8b5cf6', 'API development and backend services'),
('ç§»åŠ¨åº”ç”¨å¼€å‘', 'mobile-dev', 'ğŸ“±', '#10b981', 'Mobile application development'),
('Web & å‰ç«¯å¼€å‘', 'web-frontend', 'ğŸŒ', '#06b6d4', 'Web and frontend development'),
('ä½/æ— ä»£ç å¹³å°', 'nocode-lowcode', 'ğŸš€', '#84cc16', 'No-code and low-code automation platforms'),
('ç½‘ç»œå®‰å…¨ & éšç§', 'cybersecurity', 'ğŸ”’', '#dc2626', 'Cybersecurity and privacy protection'),
('AI & æœºå™¨å­¦ä¹ ', 'ai-ml', 'ğŸ¤–', '#8b5cf6', 'Artificial intelligence and machine learning'),
('ç”µå•† & é›¶å”®', 'ecommerce', 'ğŸ›’', '#f59e0b', 'E-commerce and retail platforms'),
('å¥åº· & å¥èº«ç§‘æŠ€', 'healthtech', 'ğŸ¥', '#ef4444', 'Healthcare and fitness technology'),
('æ•™è‚²ç§‘æŠ€', 'edtech', 'ğŸ“š', '#06b6d4', 'Educational technology platforms'),
('é‡‘èç§‘æŠ€', 'fintech', 'ğŸ’°', '#10b981', 'Financial technology and digital banking'),
('æ¶ˆè´¹è€…æœåŠ¡', 'consumer-services', 'ğŸ ', '#f97316', 'Consumer and local services'),
('ä¼ä¸šæœåŠ¡ & B2B', 'b2b-enterprise', 'ğŸ¢', '#6366f1', 'Enterprise and B2B services'),
('åª’ä½“ & å†…å®¹åˆ›ä½œ', 'media-content', 'ğŸ¨', '#ec4899', 'Media and content creation platforms'),
('æ—…æ¸¸ & å‡ºè¡Œ', 'travel-transport', 'âœˆï¸', '#22c55e', 'Travel and transportation services'),
('ç¤¾äº¤ & ç¤¾åŒº', 'social-community', 'ğŸ‘¥', '#ec4899', 'Social networks and community platforms'),
('ç»¿è‰² & å¯æŒç»­ç§‘æŠ€', 'greentech-sustainability', 'ğŸŒ±', '#22c55e', 'Green technology and sustainability solutions'),
('ç‰©æµ & ä¾›åº”é“¾', 'logistics-supply', 'ğŸ“¦', '#64748b', 'Logistics and supply chain management'),
('æ¸¸æˆ & å¨±ä¹', 'gaming-entertainment', 'ğŸ®', '#f97316', 'Gaming and entertainment platforms')
ON CONFLICT (slug) DO NOTHING;

-- Add missing columns if they don't exist (for existing databases)
DO $$ 
BEGIN
    -- Add confidence_score if it doesn't exist
    IF NOT EXISTS (SELECT 1 FROM information_schema.columns 
                   WHERE table_name = 'startup_ideas' AND column_name = 'confidence_score') THEN
        ALTER TABLE startup_ideas ADD COLUMN confidence_score INTEGER DEFAULT 0;
    END IF;
    
    -- Add source_post_ids if it doesn't exist
    IF NOT EXISTS (SELECT 1 FROM information_schema.columns 
                   WHERE table_name = 'startup_ideas' AND column_name = 'source_post_ids') THEN
        ALTER TABLE startup_ideas ADD COLUMN source_post_ids INTEGER[] DEFAULT '{}';
    END IF;
END $$;

-- Create RLS policies
ALTER TABLE startup_ideas ENABLE ROW LEVEL SECURITY;
ALTER TABLE industries ENABLE ROW LEVEL SECURITY;
ALTER TABLE daily_stats ENABLE ROW LEVEL SECURITY;
ALTER TABLE raw_reddit_posts ENABLE ROW LEVEL SECURITY;

-- Allow public read access
CREATE POLICY "Allow public read access on startup_ideas" ON startup_ideas FOR SELECT USING (true);
CREATE POLICY "Allow public read access on industries" ON industries FOR SELECT USING (true);
CREATE POLICY "Allow public read access on daily_stats" ON daily_stats FOR SELECT USING (true);
CREATE POLICY "Allow public read access on raw_reddit_posts" ON raw_reddit_posts FOR SELECT USING (true);

-- Allow service role full access
CREATE POLICY "Allow service role full access on startup_ideas" ON startup_ideas FOR ALL USING (auth.role() = 'service_role');
CREATE POLICY "Allow service role full access on industries" ON industries FOR ALL USING (auth.role() = 'service_role');
CREATE POLICY "Allow service role full access on daily_stats" ON daily_stats FOR ALL USING (auth.role() = 'service_role');
CREATE POLICY "Allow service role full access on raw_reddit_posts" ON raw_reddit_posts FOR ALL USING (auth.role() = 'service_role');

-- Create indexes for better performance
CREATE INDEX IF NOT EXISTS idx_startup_ideas_industry_id ON startup_ideas(industry_id);
CREATE INDEX IF NOT EXISTS idx_startup_ideas_created_at ON startup_ideas(created_at);
CREATE INDEX IF NOT EXISTS idx_startup_ideas_upvotes ON startup_ideas(upvotes);
CREATE INDEX IF NOT EXISTS idx_startup_ideas_confidence_score ON startup_ideas(confidence_score);
CREATE INDEX IF NOT EXISTS idx_raw_reddit_posts_industry_id ON raw_reddit_posts(industry_id);
CREATE INDEX IF NOT EXISTS idx_raw_reddit_posts_created_at ON raw_reddit_posts(created_at);
CREATE INDEX IF NOT EXISTS idx_raw_reddit_posts_reddit_id ON raw_reddit_posts(reddit_id);

-- Create indexes for performance
CREATE INDEX IF NOT EXISTS idx_raw_reddit_posts_industry_analyzed ON raw_reddit_posts (industry_id, analyzed);
CREATE INDEX IF NOT EXISTS idx_raw_reddit_posts_scraped_at ON raw_reddit_posts (scraped_at);
CREATE INDEX IF NOT EXISTS idx_startup_ideas_industry ON startup_ideas (industry_id);
CREATE INDEX IF NOT EXISTS idx_startup_ideas_created_at ON startup_ideas (created_at);
CREATE INDEX IF NOT EXISTS idx_scrape_tasks_status_batch ON scrape_tasks (status, batch_id);
CREATE INDEX IF NOT EXISTS idx_scrape_tasks_created_at ON scrape_tasks (created_at);
CREATE INDEX IF NOT EXISTS idx_scrape_tasks_industry_status ON scrape_tasks (industry_id, status);

-- æ–°å¢é”ç›¸å…³ç´¢å¼•
CREATE INDEX IF NOT EXISTS idx_scrape_tasks_lock ON scrape_tasks (status, industry_id, created_at) 
  WHERE status IN ('coordinator_lock', 'analyzer_lock');

-- æ–°å¢è¶…æ—¶ä»»åŠ¡æ£€æŸ¥ç´¢å¼•
CREATE INDEX IF NOT EXISTS idx_scrape_tasks_timeout ON scrape_tasks (status, started_at)
  WHERE status IN ('scraping', 'analyzing');

-- æ–°å¢é‡è¯•ä»»åŠ¡æŸ¥è¯¢ç´¢å¼•
CREATE INDEX IF NOT EXISTS idx_scrape_tasks_retry ON scrape_tasks (status, retry_count, completed_at)
  WHERE status = 'failed';

-- åˆ›å»ºæ¸…ç†è¿‡æœŸé”çš„å‡½æ•°
CREATE OR REPLACE FUNCTION cleanup_expired_locks()
RETURNS void AS $$
BEGIN
  -- æ¸…ç†è¿‡æœŸçš„coordinatoré”
  DELETE FROM scrape_tasks 
  WHERE status IN ('coordinator_lock', 'analyzer_lock')
    AND industry_id < 0
    AND created_at < NOW();
    
  -- è®°å½•æ¸…ç†æ—¥å¿—
  RAISE NOTICE 'Cleaned up expired coordinator locks at %', NOW();
END;
$$ LANGUAGE plpgsql;

-- åˆ›å»ºä»»åŠ¡è¶…æ—¶æ£€æµ‹å‡½æ•°
CREATE OR REPLACE FUNCTION check_timeout_tasks()
RETURNS TABLE(
  timeout_count INTEGER,
  reset_count INTEGER,
  failed_count INTEGER
) AS $$
DECLARE
  timeout_threshold TIMESTAMP := NOW() - INTERVAL '10 minutes';
  retry_threshold TIMESTAMP := NOW() - INTERVAL '1 hour';
  timeout_tasks_count INTEGER := 0;
  reset_tasks_count INTEGER := 0;
  failed_tasks_count INTEGER := 0;
BEGIN
  -- ç»Ÿè®¡è¶…æ—¶ä»»åŠ¡
  SELECT COUNT(*) INTO timeout_tasks_count
  FROM scrape_tasks 
  WHERE status IN ('scraping', 'analyzing')
    AND started_at < timeout_threshold;
    
  -- é‡ç½®å¯é‡è¯•çš„è¶…æ—¶ä»»åŠ¡
  WITH retryable_tasks AS (
    UPDATE scrape_tasks 
    SET status = CASE 
                  WHEN status = 'scraping' THEN 'pending_scrape'
                  WHEN status = 'analyzing' THEN 'complete_scrape'
                 END,
        retry_count = retry_count + 1,
        error_message = status || ' timeout, retrying...',
        started_at = NULL
    WHERE status IN ('scraping', 'analyzing')
      AND started_at < timeout_threshold
      AND retry_count < max_retries
    RETURNING id
  )
  SELECT COUNT(*) INTO reset_tasks_count FROM retryable_tasks;
  
  -- æ ‡è®°è¶…è¿‡é‡è¯•æ¬¡æ•°çš„è¶…æ—¶ä»»åŠ¡ä¸ºå¤±è´¥
  WITH failed_tasks AS (
    UPDATE scrape_tasks 
    SET status = 'failed',
        error_message = status || ' timeout, max retries exceeded',
        completed_at = NOW()
    WHERE status IN ('scraping', 'analyzing')
      AND started_at < timeout_threshold
      AND retry_count >= max_retries
    RETURNING id
  )
  SELECT COUNT(*) INTO failed_tasks_count FROM failed_tasks;
  
  RETURN QUERY SELECT timeout_tasks_count, reset_tasks_count, failed_tasks_count;
END;
$$ LANGUAGE plpgsql;

-- åˆ›å»ºé‡è¯•å¤±è´¥ä»»åŠ¡çš„å‡½æ•°
CREATE OR REPLACE FUNCTION retry_failed_tasks()
RETURNS TABLE(
  retried_count INTEGER
) AS $$
DECLARE
  retry_threshold TIMESTAMP := NOW() - INTERVAL '1 hour';
  retried_tasks_count INTEGER := 0;
BEGIN
  -- é‡è¯•ç¬¦åˆæ¡ä»¶çš„å¤±è´¥ä»»åŠ¡
  WITH retry_tasks AS (
    UPDATE scrape_tasks 
    SET status = CASE 
                  WHEN error_message LIKE '%scraping%' OR error_message LIKE '%reddit%' THEN 'pending_scrape'
                  WHEN error_message LIKE '%analysis%' OR error_message LIKE '%deepseek%' THEN 'complete_scrape'
                  ELSE 'pending_scrape'
                 END,
        retry_count = retry_count + 1,
        error_message = NULL,
        started_at = NULL,
        completed_at = NULL
    WHERE status = 'failed'
      AND retry_count < max_retries
      AND completed_at < retry_threshold
    RETURNING id
  )
  SELECT COUNT(*) INTO retried_tasks_count FROM retry_tasks;
  
  RETURN QUERY SELECT retried_tasks_count;
END;
$$ LANGUAGE plpgsql;